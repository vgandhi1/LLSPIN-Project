{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinaygandhi\\AppData\\Local\\anaconda3\\envs\\tf1\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-04-19 09:20:39,493] A new study created in memory with name: no-name-af643953-17c5-4158-9ac0-90d7d225a99d\n",
      "[I 2025-04-19 09:20:49,803] Trial 0 finished with value: 0.014104698784649372 and parameters: {'lam': 0.0012894907519001152, 'lr': 0.023493636517030354, 'num_epoch': 2000}. Best is trial 0 with value: 0.014104698784649372.\n",
      "[I 2025-04-19 09:22:14,566] Trial 1 finished with value: 0.0029720175080001354 and parameters: {'lam': 0.0049765707771699235, 'lr': 0.1333533151010355, 'num_epoch': 15000}. Best is trial 1 with value: 0.0029720175080001354.\n",
      "[I 2025-04-19 09:22:25,009] Trial 2 finished with value: 0.013791070319712162 and parameters: {'lam': 0.00894024852670445, 'lr': 0.016457086755752862, 'num_epoch': 2000}. Best is trial 1 with value: 0.0029720175080001354.\n",
      "[I 2025-04-19 09:23:51,916] Trial 3 finished with value: 0.007538485806435347 and parameters: {'lam': 0.0018639966204838923, 'lr': 0.018131600890847685, 'num_epoch': 15000}. Best is trial 1 with value: 0.0029720175080001354.\n",
      "[I 2025-04-19 09:25:13,504] Trial 4 finished with value: 0.012533407658338547 and parameters: {'lam': 0.001266860844712103, 'lr': 0.060451092642462886, 'num_epoch': 15000}. Best is trial 1 with value: 0.0029720175080001354.\n",
      "[I 2025-04-19 09:25:24,054] Trial 5 finished with value: 0.011731174774467945 and parameters: {'lam': 0.00873082270750198, 'lr': 0.0478385914295616, 'num_epoch': 2000}. Best is trial 1 with value: 0.0029720175080001354.\n",
      "[I 2025-04-19 09:25:34,985] Trial 6 finished with value: 0.018129484727978706 and parameters: {'lam': 0.0019139148300918456, 'lr': 0.16679199345191376, 'num_epoch': 2000}. Best is trial 1 with value: 0.0029720175080001354.\n",
      "[I 2025-04-19 09:26:02,028] Trial 7 finished with value: 0.002726164646446705 and parameters: {'lam': 0.0012945230682803077, 'lr': 0.10038246187255012, 'num_epoch': 5000}. Best is trial 7 with value: 0.002726164646446705.\n",
      "[I 2025-04-19 09:26:28,883] Trial 8 finished with value: 0.0037970368284732103 and parameters: {'lam': 0.008872829409733203, 'lr': 0.037345822368081434, 'num_epoch': 5000}. Best is trial 7 with value: 0.002726164646446705.\n",
      "[I 2025-04-19 09:26:57,024] Trial 9 finished with value: 0.009135917760431767 and parameters: {'lam': 0.0018702961758030108, 'lr': 0.018419290092636452, 'num_epoch': 5000}. Best is trial 7 with value: 0.002726164646446705.\n",
      "[I 2025-04-19 09:27:51,854] Trial 10 finished with value: 0.002423263620585203 and parameters: {'lam': 0.003462784700408223, 'lr': 0.088636853212364, 'num_epoch': 10000}. Best is trial 10 with value: 0.002423263620585203.\n",
      "[I 2025-04-19 09:28:47,601] Trial 11 finished with value: 0.0030997467692941427 and parameters: {'lam': 0.003673213795981954, 'lr': 0.08986172806929456, 'num_epoch': 10000}. Best is trial 10 with value: 0.002423263620585203.\n",
      "[I 2025-04-19 09:29:39,973] Trial 12 finished with value: 0.013188961893320084 and parameters: {'lam': 0.003103172458848203, 'lr': 0.09137257685195022, 'num_epoch': 10000}. Best is trial 10 with value: 0.002423263620585203.\n",
      "[I 2025-04-19 09:30:07,471] Trial 13 finished with value: 0.008846476674079895 and parameters: {'lam': 0.0031516527730675267, 'lr': 0.0905272789392882, 'num_epoch': 5000}. Best is trial 10 with value: 0.002423263620585203.\n",
      "[I 2025-04-19 09:31:00,057] Trial 14 finished with value: 0.024227511137723923 and parameters: {'lam': 0.005364305448959918, 'lr': 0.010327068518514523, 'num_epoch': 10000}. Best is trial 10 with value: 0.002423263620585203.\n",
      "[I 2025-04-19 09:31:54,473] Trial 15 finished with value: 0.005091158673167229 and parameters: {'lam': 0.0024077656057135753, 'lr': 0.1875080715697302, 'num_epoch': 10000}. Best is trial 10 with value: 0.002423263620585203.\n",
      "[I 2025-04-19 09:32:23,408] Trial 16 finished with value: 0.012912151403725147 and parameters: {'lam': 0.0010843716783054446, 'lr': 0.06195954233781107, 'num_epoch': 5000}. Best is trial 10 with value: 0.002423263620585203.\n",
      "[I 2025-04-19 09:32:50,582] Trial 17 finished with value: 0.00777325127273798 and parameters: {'lam': 0.0047858719348778285, 'lr': 0.11181931992178246, 'num_epoch': 5000}. Best is trial 10 with value: 0.002423263620585203.\n",
      "[I 2025-04-19 09:33:41,058] Trial 18 finished with value: 0.002537837717682123 and parameters: {'lam': 0.0025363070978059606, 'lr': 0.03777229273795211, 'num_epoch': 10000}. Best is trial 10 with value: 0.002423263620585203.\n",
      "[I 2025-04-19 09:34:35,007] Trial 19 finished with value: 0.002982756355777383 and parameters: {'lam': 0.0039377336851547035, 'lr': 0.02949221919461254, 'num_epoch': 10000}. Best is trial 10 with value: 0.002423263620585203.\n",
      "[I 2025-04-19 09:35:30,012] Trial 20 finished with value: 0.0022965839598327875 and parameters: {'lam': 0.0024629066841840544, 'lr': 0.06361419972068136, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:36:23,052] Trial 21 finished with value: 0.002800669288262725 and parameters: {'lam': 0.002468375380724874, 'lr': 0.05814399667276238, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:37:17,354] Trial 22 finished with value: 0.002969068242236972 and parameters: {'lam': 0.00246236762959197, 'lr': 0.03640637988767535, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:38:13,977] Trial 23 finished with value: 0.0023316447623074055 and parameters: {'lam': 0.005992404367662341, 'lr': 0.06901719315056974, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:39:10,881] Trial 24 finished with value: 0.004348761402070522 and parameters: {'lam': 0.006354476842944408, 'lr': 0.07390302141021414, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:40:01,578] Trial 25 finished with value: 0.04244472458958626 and parameters: {'lam': 0.006162798354536658, 'lr': 0.1322486333420803, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:40:58,244] Trial 26 finished with value: 0.0033040244597941637 and parameters: {'lam': 0.003828129008501364, 'lr': 0.0745960573600223, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:41:49,708] Trial 27 finished with value: 0.0030414036009460688 and parameters: {'lam': 0.007326587250590635, 'lr': 0.05230077446360913, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:42:41,881] Trial 28 finished with value: 0.01345288846641779 and parameters: {'lam': 0.004496989247951413, 'lr': 0.069080343579431, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:43:32,078] Trial 29 finished with value: 0.008599366992712021 and parameters: {'lam': 0.0015555885567707442, 'lr': 0.028003490818159626, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:44:54,110] Trial 30 finished with value: 0.008374065160751343 and parameters: {'lam': 0.003149333458842177, 'lr': 0.1283173136006331, 'num_epoch': 15000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:45:51,888] Trial 31 finished with value: 0.0032516082283109426 and parameters: {'lam': 0.002190961188655672, 'lr': 0.037053085628946936, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:46:50,657] Trial 32 finished with value: 0.016233060508966446 and parameters: {'lam': 0.0026412815054138797, 'lr': 0.042750007976524014, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:47:50,450] Trial 33 finished with value: 0.011449063196778297 and parameters: {'lam': 0.002828643886932894, 'lr': 0.042346827329547684, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:48:02,061] Trial 34 finished with value: 0.008337166160345078 and parameters: {'lam': 0.0035857329537249275, 'lr': 0.07510115568409523, 'num_epoch': 2000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:49:31,078] Trial 35 finished with value: 0.00314771244302392 and parameters: {'lam': 0.00210093561026446, 'lr': 0.027932234232032387, 'num_epoch': 15000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:50:29,886] Trial 36 finished with value: 0.005705272313207388 and parameters: {'lam': 0.001588062724933389, 'lr': 0.05401673683800293, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:50:41,663] Trial 37 finished with value: 0.019586145877838135 and parameters: {'lam': 0.0041408864530940335, 'lr': 0.023194441902668877, 'num_epoch': 2000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:52:04,214] Trial 38 finished with value: 0.0024517204146832228 and parameters: {'lam': 0.005821520960959059, 'lr': 0.10924998034751905, 'num_epoch': 15000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:53:27,537] Trial 39 finished with value: 0.005173179320991039 and parameters: {'lam': 0.009920089352172408, 'lr': 0.16145015734244123, 'num_epoch': 15000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:54:51,919] Trial 40 finished with value: 0.0030218386091291904 and parameters: {'lam': 0.0056108006472576225, 'lr': 0.11239393092996987, 'num_epoch': 15000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 09:56:22,693] Trial 41 finished with value: 0.0025775914546102285 and parameters: {'lam': 0.0075450252018820115, 'lr': 0.06425369966957768, 'num_epoch': 15000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 10:10:31,087] Trial 42 finished with value: 0.0025485006626695395 and parameters: {'lam': 0.0028184145637261625, 'lr': 0.08393194522579575, 'num_epoch': 15000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 10:10:35,967] Trial 43 finished with value: 0.0035094672348350286 and parameters: {'lam': 0.007444385815429993, 'lr': 0.10477795986034787, 'num_epoch': 2000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 10:11:01,281] Trial 44 finished with value: 0.007447917480021715 and parameters: {'lam': 0.0016025798244366236, 'lr': 0.04750730023999006, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 10:11:56,196] Trial 45 finished with value: 0.006260444410145283 and parameters: {'lam': 0.0034404643849862307, 'lr': 0.14847906760505244, 'num_epoch': 15000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 10:12:52,736] Trial 46 finished with value: 0.014341920614242554 and parameters: {'lam': 0.004389410143194951, 'lr': 0.08762566197990118, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 10:13:51,155] Trial 47 finished with value: 0.002619219711050391 and parameters: {'lam': 0.002015172156995979, 'lr': 0.11987614235664246, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 10:14:51,679] Trial 48 finished with value: 0.0028463092166930437 and parameters: {'lam': 0.0053891213025872246, 'lr': 0.08091414250767451, 'num_epoch': 10000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 10:16:20,185] Trial 49 finished with value: 0.0036697559989988804 and parameters: {'lam': 0.006085192489543506, 'lr': 0.10083542043147183, 'num_epoch': 15000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 10:16:49,516] Trial 50 finished with value: 0.015327423810958862 and parameters: {'lam': 0.004920733657146599, 'lr': 0.03245599641619623, 'num_epoch': 5000}. Best is trial 20 with value: 0.0022965839598327875.\n",
      "[I 2025-04-19 10:18:15,792] Trial 51 finished with value: 0.0020711778197437525 and parameters: {'lam': 0.0027920605191497474, 'lr': 0.08671084950023515, 'num_epoch': 15000}. Best is trial 51 with value: 0.0020711778197437525.\n",
      "[I 2025-04-19 10:19:43,165] Trial 52 finished with value: 0.002795688109472394 and parameters: {'lam': 0.0022440278735702678, 'lr': 0.09542457039960373, 'num_epoch': 15000}. Best is trial 51 with value: 0.0020711778197437525.\n",
      "[I 2025-04-19 10:21:10,563] Trial 53 finished with value: 0.0027238803450018167 and parameters: {'lam': 0.002966718479907528, 'lr': 0.06701713543854994, 'num_epoch': 15000}. Best is trial 51 with value: 0.0020711778197437525.\n",
      "[I 2025-04-19 10:22:38,658] Trial 54 finished with value: 0.0025044966023415327 and parameters: {'lam': 0.0017236993652163714, 'lr': 0.05551549426700592, 'num_epoch': 15000}. Best is trial 51 with value: 0.0020711778197437525.\n",
      "[I 2025-04-19 10:24:06,021] Trial 55 finished with value: 0.00630370806902647 and parameters: {'lam': 0.001380216996138283, 'lr': 0.05730171785673313, 'num_epoch': 15000}. Best is trial 51 with value: 0.0020711778197437525.\n",
      "[I 2025-04-19 10:25:30,474] Trial 56 finished with value: 0.002358437515795231 and parameters: {'lam': 0.0017318060171295892, 'lr': 0.05227431415715127, 'num_epoch': 15000}. Best is trial 51 with value: 0.0020711778197437525.\n",
      "[I 2025-04-19 10:26:53,430] Trial 57 finished with value: 0.003145978320389986 and parameters: {'lam': 0.0010633469750346602, 'lr': 0.19500987773706124, 'num_epoch': 15000}. Best is trial 51 with value: 0.0020711778197437525.\n",
      "[I 2025-04-19 10:28:21,246] Trial 58 finished with value: 0.00605812668800354 and parameters: {'lam': 0.0033790037370329783, 'lr': 0.07927433572838678, 'num_epoch': 15000}. Best is trial 51 with value: 0.0020711778197437525.\n",
      "[I 2025-04-19 10:29:42,021] Trial 59 finished with value: 0.0059081981889903545 and parameters: {'lam': 0.00184161574893889, 'lr': 0.0478290977098098, 'num_epoch': 15000}. Best is trial 51 with value: 0.0020711778197437525.\n",
      "[I 2025-04-19 10:30:09,592] Trial 60 finished with value: 0.013494384475052357 and parameters: {'lam': 0.006560448200816063, 'lr': 0.011607860540677464, 'num_epoch': 5000}. Best is trial 51 with value: 0.0020711778197437525.\n",
      "[I 2025-04-19 10:31:35,687] Trial 61 finished with value: 0.007399707101285458 and parameters: {'lam': 0.001732131485759926, 'lr': 0.06147092679519183, 'num_epoch': 15000}. Best is trial 51 with value: 0.0020711778197437525.\n",
      "[I 2025-04-19 10:33:03,452] Trial 62 finished with value: 0.0018176974263042212 and parameters: {'lam': 0.001204807885393672, 'lr': 0.0519488857195382, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:34:30,424] Trial 63 finished with value: 0.005550859030336142 and parameters: {'lam': 0.001006609385562292, 'lr': 0.07033901450615888, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:35:58,797] Trial 64 finished with value: 0.0022649518214166164 and parameters: {'lam': 0.0012290898760781142, 'lr': 0.05294349079741014, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:36:10,638] Trial 65 finished with value: 0.008587801828980446 and parameters: {'lam': 0.00119928159579004, 'lr': 0.05187505747583816, 'num_epoch': 2000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:37:37,971] Trial 66 finished with value: 0.01730785332620144 and parameters: {'lam': 0.0013865612135269025, 'lr': 0.04513286314976871, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:38:52,235] Trial 67 finished with value: 0.003656162414699793 and parameters: {'lam': 0.001190003589162189, 'lr': 0.04073136394271109, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:39:37,785] Trial 68 finished with value: 0.004896624945104122 and parameters: {'lam': 0.001356328585543162, 'lr': 0.061882519481053534, 'num_epoch': 10000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:40:01,128] Trial 69 finished with value: 0.0021933631505817175 and parameters: {'lam': 0.0014879375471935562, 'lr': 0.051775189425210436, 'num_epoch': 5000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:40:24,266] Trial 70 finished with value: 0.004217651207000017 and parameters: {'lam': 0.0015097958216013741, 'lr': 0.049991888699914784, 'num_epoch': 5000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:40:47,852] Trial 71 finished with value: 0.010653060860931873 and parameters: {'lam': 0.0011990855115746313, 'lr': 0.05776998012247099, 'num_epoch': 5000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:41:10,666] Trial 72 finished with value: 0.004486196208745241 and parameters: {'lam': 0.0022966308949094933, 'lr': 0.06977042552291675, 'num_epoch': 5000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:41:33,505] Trial 73 finished with value: 0.005768141243606806 and parameters: {'lam': 0.0012632942048661096, 'lr': 0.07678633890265912, 'num_epoch': 5000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:42:19,015] Trial 74 finished with value: 0.003467485774308443 and parameters: {'lam': 0.0011165290864617954, 'lr': 0.03320239381868877, 'num_epoch': 10000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:43:28,242] Trial 75 finished with value: 0.002105266321450472 and parameters: {'lam': 0.0019414342974211935, 'lr': 0.0398791351541916, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:44:39,475] Trial 76 finished with value: 0.004228687379509211 and parameters: {'lam': 0.0014848519415435824, 'lr': 0.04101678809137183, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:45:48,653] Trial 77 finished with value: 0.002812005812302232 and parameters: {'lam': 0.0017058447836506207, 'lr': 0.04592053204176424, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:46:57,438] Trial 78 finished with value: 0.004231500439345837 and parameters: {'lam': 0.0019547645594071156, 'lr': 0.05268993028093702, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:48:06,514] Trial 79 finished with value: 0.003351490246132016 and parameters: {'lam': 0.0014518812648276682, 'lr': 0.03783430745800702, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:48:15,683] Trial 80 finished with value: 0.00942376721650362 and parameters: {'lam': 0.002623926819880197, 'lr': 0.0632284579620348, 'num_epoch': 2000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:49:02,298] Trial 81 finished with value: 0.0028404139447957277 and parameters: {'lam': 0.001831049306865898, 'lr': 0.08467156999383407, 'num_epoch': 10000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:50:12,589] Trial 82 finished with value: 0.0033529186621308327 and parameters: {'lam': 0.002350268869095838, 'lr': 0.09389111909025077, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:51:00,729] Trial 83 finished with value: 0.002772142644971609 and parameters: {'lam': 0.0020919308455108403, 'lr': 0.06612157766134083, 'num_epoch': 10000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:51:24,225] Trial 84 finished with value: 0.0056451307609677315 and parameters: {'lam': 0.001283958167467687, 'lr': 0.0486559976542618, 'num_epoch': 5000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:52:35,702] Trial 85 finished with value: 0.003128653857856989 and parameters: {'lam': 0.002663496152685774, 'lr': 0.07228436598472704, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:53:22,932] Trial 86 finished with value: 0.0025576469488441944 and parameters: {'lam': 0.0016076739273049698, 'lr': 0.05801520693903504, 'num_epoch': 10000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:54:34,157] Trial 87 finished with value: 0.004742181859910488 and parameters: {'lam': 0.0028845444166969553, 'lr': 0.044364852899696494, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:55:21,373] Trial 88 finished with value: 0.004957397468388081 and parameters: {'lam': 0.0011256252124533948, 'lr': 0.03396104143029833, 'num_epoch': 10000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:56:29,333] Trial 89 finished with value: 0.0040960232727229595 and parameters: {'lam': 0.002183472807755123, 'lr': 0.05463929148528537, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:56:52,470] Trial 90 finished with value: 0.015029976144433022 and parameters: {'lam': 0.008202337789935031, 'lr': 0.04016629564956452, 'num_epoch': 5000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:57:59,421] Trial 91 finished with value: 0.007387306075543165 and parameters: {'lam': 0.00570449563667174, 'lr': 0.10651850545770399, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 10:59:09,098] Trial 92 finished with value: 0.004066504072397947 and parameters: {'lam': 0.0066742790228195, 'lr': 0.09768022692337566, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 11:00:18,060] Trial 93 finished with value: 0.0037388275377452374 and parameters: {'lam': 0.003045307928702752, 'lr': 0.14473430355222655, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 11:01:29,361] Trial 94 finished with value: 0.00621290085837245 and parameters: {'lam': 0.0016639576086581098, 'lr': 0.11433559050663313, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 11:02:39,648] Trial 95 finished with value: 0.007133061531931162 and parameters: {'lam': 0.004607900659302631, 'lr': 0.0777571564916815, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 11:03:26,038] Trial 96 finished with value: 0.0032718204893171787 and parameters: {'lam': 0.003866090471368707, 'lr': 0.08867406958676234, 'num_epoch': 10000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 11:03:35,288] Trial 97 finished with value: 0.012683333829045296 and parameters: {'lam': 0.00423340743042728, 'lr': 0.04989049605317327, 'num_epoch': 2000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 11:04:45,827] Trial 98 finished with value: 0.007507622707635164 and parameters: {'lam': 0.0069072642047859475, 'lr': 0.08314451153887148, 'num_epoch': 15000}. Best is trial 62 with value: 0.0018176974263042212.\n",
      "[I 2025-04-19 11:05:32,821] Trial 99 finished with value: 0.0023572295904159546 and parameters: {'lam': 0.002471731245390212, 'lr': 0.06642044728599797, 'num_epoch': 10000}. Best is trial 62 with value: 0.0018176974263042212.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "FrozenTrial(number=62, state=TrialState.COMPLETE, values=[0.0018176974263042212], datetime_start=datetime.datetime(2025, 4, 19, 10, 31, 35, 688523), datetime_complete=datetime.datetime(2025, 4, 19, 10, 33, 3, 451174), params={'lam': 0.001204807885393672, 'lr': 0.0519488857195382, 'num_epoch': 15000}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'lam': FloatDistribution(high=0.01, log=True, low=0.001, step=None), 'lr': FloatDistribution(high=0.2, log=True, low=0.01, step=None), 'num_epoch': CategoricalDistribution(choices=(2000, 5000, 10000, 15000))}, trial_id=62, value=None)\n",
      "Test MSE: 0.001964\n",
      "Test RÂ² : 0.955056\n",
      "Test Acc: 0.9500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1400x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# llspin_pytorch.py\n",
    "# Full 1-to-1 PyTorch implementation of the LLSPIN model using updated 5-feature synthetic equation and batch gradient descent\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, colors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os\n",
    "import random\n",
    "import optuna\n",
    "\n",
    "# -----------------------------\n",
    "# 0. Set seed for reproducibility\n",
    "# -----------------------------\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(32)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Updated Synthetic Data Generation\n",
    "# -----------------------------\n",
    "def linear_simple_data_gen(n_sample=300, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    Xs1 = rng.normal(loc=1, scale=0.5, size=(n_sample, 5))\n",
    "    Ys1 = -2 * Xs1[:, 0] + 1 * Xs1[:, 1] - 0.5 * Xs1[:, 2]\n",
    "    Xs2 = rng.normal(loc=-1, scale=0.5, size=(n_sample, 5))\n",
    "    Ys2 = -0.5 * Xs2[:, 2] + 1 * Xs2[:, 3] - 2 * Xs2[:, 4]\n",
    "\n",
    "    X_data = np.concatenate((Xs1, Xs2), axis=0)\n",
    "    Y_data = np.concatenate((Ys1.reshape(-1, 1), Ys2.reshape(-1, 1)), axis=0)\n",
    "    Y_data = (Y_data - Y_data.min()) / (Y_data.max() - Y_data.min())\n",
    "    labels = np.concatenate((np.ones(n_sample), np.full(n_sample, 2)))\n",
    "    Y_data = np.concatenate((Y_data, labels.reshape(-1, 1)), axis=1)\n",
    "    return X_data.astype(np.float32), Y_data.astype(np.float32)\n",
    "\n",
    "# ----------------------\n",
    "# 2. LLSPIN Components (included here for execution)\n",
    "# ----------------------\n",
    "class HardSigmoid(nn.Module):\n",
    "    def __init__(self, a):\n",
    "        super().__init__()\n",
    "        self.a = a\n",
    "    def forward(self, x):\n",
    "        return torch.clamp(self.a * x + 0.5, 0., 1.)\n",
    "\n",
    "class GatingNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers, a, sigma):\n",
    "        super().__init__()\n",
    "        self.a = a\n",
    "        self.sigma = sigma\n",
    "        layers = []\n",
    "        last_dim = input_dim\n",
    "        for h in hidden_layers:\n",
    "            layers.append(nn.Linear(last_dim, h))\n",
    "            layers.append(nn.Tanh())\n",
    "            last_dim = h\n",
    "        self.hidden = nn.Sequential(*layers)\n",
    "        self.alpha_layer = nn.Linear(last_dim, input_dim)\n",
    "        self.hard_sigmoid = HardSigmoid(a)\n",
    "    def forward(self, x, is_training=True):\n",
    "        alpha = self.alpha_layer(self.hidden(x))\n",
    "        if is_training:\n",
    "            noise = torch.randn_like(alpha) * self.sigma\n",
    "            z = alpha + noise\n",
    "            gate = self.hard_sigmoid(z)\n",
    "        else:\n",
    "            gate = self.hard_sigmoid(alpha)\n",
    "        return gate, alpha\n",
    "\n",
    "class PredictionNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers, output_dim):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        last_dim = input_dim\n",
    "        for h in hidden_layers[:-1]:\n",
    "            layers.append(nn.Linear(last_dim, h))\n",
    "            layers.append(nn.Tanh())\n",
    "            last_dim = h\n",
    "        layers.append(nn.Linear(last_dim, hidden_layers[-1]))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class LSPIN(nn.Module):\n",
    "    def __init__(self, input_dim, pred_hidden, output_dim, gate_hidden, a, sigma, lam, feature_selection=True):\n",
    "        super().__init__()\n",
    "        self.feature_selection = feature_selection\n",
    "        self.a = a\n",
    "        self.sigma = sigma\n",
    "        self.lam = lam\n",
    "        if self.feature_selection:\n",
    "            self.gating_net = GatingNetwork(input_dim, gate_hidden, a, sigma)\n",
    "        self.pred_net = PredictionNetwork(input_dim, pred_hidden, output_dim)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "    def forward(self, x, y=None, train_gates=True):\n",
    "        if self.feature_selection:\n",
    "            gates, alpha = self.gating_net(x, is_training=train_gates)\n",
    "            x = x * gates\n",
    "        else:\n",
    "            alpha = None\n",
    "        logits = self.pred_net(x)\n",
    "        output = {'logits': logits, 'alpha': alpha}\n",
    "        if y is not None:\n",
    "            output['loss'] = self.loss_fn(logits, y)\n",
    "        return output\n",
    "    def get_prob_alpha(self, x):\n",
    "        with torch.no_grad():\n",
    "            _, alpha = self.gating_net(x, is_training=False)\n",
    "            return self.gating_net.hard_sigmoid(alpha).cpu().numpy()\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Optuna-Compatible Training Loop \n",
    "# ----------------------------\n",
    "def train_llspin_with_params(lam, lr, num_epoch):\n",
    "    X_data, Y_data = linear_simple_data_gen()\n",
    "    X_train, X_remain, yc_train, yc_remain = train_test_split(X_data, Y_data, train_size=0.8, random_state=42)\n",
    "    X_valid, X_test, yc_valid, yc_test = train_test_split(X_remain, yc_remain, train_size=0.5, random_state=42)\n",
    "    X_train, _, yc_train, _ = train_test_split(X_train, yc_train, train_size=10, random_state=42)\n",
    "\n",
    "    y_train = yc_train[:, 0:1]\n",
    "    y_valid = yc_valid[:, 0:1]\n",
    "    y_test = yc_test[:, 0:1]\n",
    "    train_label = yc_train[:, 1]\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train)\n",
    "    y_train_tensor = torch.tensor(y_train)\n",
    "\n",
    "    model = LSPIN(\n",
    "        input_dim=5,\n",
    "        pred_hidden=[100, 100, 10, 1],\n",
    "        output_dim=1,\n",
    "        gate_hidden=[10],\n",
    "        a=1,\n",
    "        sigma=0.5,\n",
    "        lam=lam\n",
    "    )\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        output = model(X_train_tensor, y_train_tensor, train_gates=True)\n",
    "        loss = output['loss']\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_output = model(torch.tensor(X_valid), torch.tensor(y_valid), train_gates=False)\n",
    "        val_loss = val_output['loss'].item()\n",
    "\n",
    "    return val_loss, model, (X_test, y_test, train_label, X_train_tensor)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Optuna Objective Function\n",
    "# ----------------------------\n",
    "def optuna_objective(trial):\n",
    "    lam = trial.suggest_float('lam', 1e-3, 1e-2, log=True)\n",
    "    lr = trial.suggest_float('lr', 1e-2, 2e-1, log=True)\n",
    "    num_epoch = trial.suggest_categorical('num_epoch', [2000, 5000, 10000, 15000])\n",
    "    val_loss, _, _ = train_llspin_with_params(lam, lr, num_epoch)\n",
    "    return val_loss\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Run Optuna Study\n",
    "# ----------------------------\n",
    "def run_optuna_study():\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(optuna_objective, n_trials=100)\n",
    "    print(\"Best trial:\")\n",
    "    print(study.best_trial)\n",
    "\n",
    "    # Re-train the best model\n",
    "    best_params = study.best_trial.params\n",
    "    val_loss, model, (X_test, y_test, train_label, X_train_tensor) = train_llspin_with_params(\n",
    "        best_params['lam'], best_params['lr'], best_params['num_epoch']\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(torch.tensor(X_test))['logits'].cpu().numpy()\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        acc = np.mean((y_pred > 0.5).astype(int) == (y_test > 0.5).astype(int))\n",
    "        print(f\"Test MSE: {mse:.6f}\\nTest RÂ² : {r2:.6f}\\nTest Acc: {acc:.4f}\")\n",
    "\n",
    "    gate_mat_train = model.get_prob_alpha(X_train_tensor)\n",
    "    ref_feat_mat_train = np.array([[1, 1, 1, 0, 0] if lbl == 1 else [0, 0, 1, 1, 1] for lbl in train_label])\n",
    "    sorted_order = np.concatenate((np.where(train_label == 1)[0], np.where(train_label == 2)[0]))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    cmap = cm.Blues\n",
    "    norm = colors.BoundaryNorm([0, 0.5, 1], cmap.N)\n",
    "\n",
    "    axes[0].imshow(ref_feat_mat_train[sorted_order], aspect='auto', cmap=cmap, norm=norm)\n",
    "    axes[0].set_title(\"Ground Truth\")\n",
    "    axes[0].set_xlabel(\"Feature Index\")\n",
    "    axes[0].set_ylabel(\"Sample Index\")\n",
    "\n",
    "    im2 = axes[1].imshow(gate_mat_train[sorted_order], aspect='auto', cmap=cmap)\n",
    "    axes[1].set_title(\"LLSPIN Gates\")\n",
    "    axes[1].set_xlabel(\"Feature Index\")\n",
    "\n",
    "    plt.colorbar(im2, ax=axes[1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_optuna_study()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf1)",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
